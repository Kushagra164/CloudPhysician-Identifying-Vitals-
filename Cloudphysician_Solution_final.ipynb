{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iQdRC6C6D9v"
      },
      "source": [
        "# **(CloudPhysician) THE VITAL EXTRACTION CHALLENGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhbsxJi8mglo"
      },
      "source": [
        "#***README File***\n",
        "#Introduction\n",
        "This collab notebook takes in the paths of images of different patient monitors, and outputs the values shown on the monitor, which are HR, SPO2, RR, SBP, DBP and MAP respectively. This notebook is made as a solution of the inter-IIT 2023 Problem Statement 6 - The Vital Extraction Challenge (By CloudPhysician)\n",
        "\n",
        "#How to run\n",
        "For the first time run, run the first block of 'Installing Necessities, Importing essential Libraries and models - '. It will load all the necessities into the memory, to be read for the inference function.\n",
        "This block needs to be run only once, and it will take 20-30 seconds to run.\n",
        "\n",
        "Also run all the blocks below the first block inorder to define the necessary functions.\n",
        "\n",
        "**Note** - The SegmentationModel.h5 file present in the zip file should also be present in the Collab environment inorder for the notebook to run.\n",
        "\n",
        "To run the functions, Run the inference function in the Final Function block. \n",
        "\n",
        "#Pipeline\n",
        "Our Team divided the task into 2 subtasks - \n",
        "\n",
        "\n",
        "*   Finding the monitor in the image and cropping it.\n",
        "*   Finding all the details on the monitor and finding which detail is which and generating the output accordingly.\n",
        "\n",
        "For finding the monitor coordinates, we are using an deep CNN network, with an EfficientNetB4 backbone (pretrained imagenet weights). The model took in resized images from (1280,720) pixels to (380,380) pixels dimensions. We augmented the 2000 images of the segmentation dataset given to us, and created a dataset of 8000 images, and trained the model onto it. The rms error after training for 50 epochs, was 6.87, and validation rms error was 8.67.\n",
        "\n",
        "The model is built, trained, and deployed via the keras API of tensorflow.\n",
        "\n",
        "Also, the model is run on padded images (600 width, 338 height), inorder to give better accuracy on images which are really close to the edge of the image.\n",
        "\n",
        "<img src = https://cdn.discordapp.com/attachments/1072573248493076563/1072573373495918632/output.png>\n",
        "\n",
        "For finding all the details on the cropped Image, PaddleOCR is used. It detects all the text and the numbers present in the image, and stores it in a numpy array. It stores the word/number detected, the bounding box of the number detected and the confidence level of it.\n",
        "\n",
        "<img>\n",
        "\n",
        "After this, we use an algorithmic approach to find out all the relevant numbers - \n",
        "\n",
        "\n",
        "*   Firstly, we delete all the detections which are smaller than a minimum threshold value, inorder to eliminate noise from the detections.\n",
        "*   Then we detect the HR in the image. We find any keywords equal or related to the word 'HR' (that might be present on the monitor) and print the closest integer to it. If no such word is found, we look at the numbers which are colored green, and print them out.If still not found we compare the respective values and take the topmost value finally.\n",
        "*   By finding out the word SpO2 or similiar words and finding the numbers closest to it we get SpO2.\n",
        "*   Similarly we find out the RR by looking for keyword 'rr','resp' and if not found we look for numbers under 45 and take them as RR. \n",
        "*   Then, we are using 4 different methods to detect BP and MAP in the image - \n",
        "    *   We first try to detect the BP by finding either '/' ad then if we get the value we are taking the first part as SBP and after '/' part as DBP.\n",
        "    *   Our second attempt to find the BP is by looking for keywords like 'sys', '5y5', '5u5', 'dia', 'mmhg', 'winhg','nibp', 'nbp'. and then finding the nearest bounding boxes to it.\n",
        "    *   We find Map by looking for '(' or ')'  and then if we got it we will take the numbers after '(' or before')'.If not found then we look for the keyword 'map' and find the bounding box nearest to it\n",
        "    *   The last attempt to find out the BP and MAP is by looking for three numbers having closest distance and within distances  within a threshold and then trying to find the SBP,DBP and MAPs\n",
        "*   After all that, we are simply arranging it all in a dictionary and outputting it.  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Libraries used - \n",
        "\n",
        "\n",
        "*   Tensorflow (for running keras models)\n",
        "*   OpenCV (for image processing)\n",
        "*   PaddleOCR (for OCR functionality)\n",
        "*   Numpy (for array calculations)\n",
        "*   ColorThief (for finding dominant colors)\n",
        "*   Matplotlib (for plotting HR graphs)\n",
        "*   Deskew (for deskewing the original images)\n",
        "*   NueroKit2 (for displaying HR graph from Heart rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyM3baQIgGSI"
      },
      "source": [
        "#Installing Necessities, Importing essential Libraries and models -\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEqbCMvjba2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fbf6d5c-e7c5-4240-9aee-e5231ddb9e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:26\n",
            "🔁 Restarting kernel...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.9.0\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/paddle_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    ld_impl_linux-64-2.40      |       h41732ed_0         688 KB  conda-forge\n",
            "    openssl-3.0.7              |       h0b41bf4_2         2.5 MB  conda-forge\n",
            "    pip-23.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n",
            "    python-3.8.16              |he550d4f_1_cpython        21.8 MB  conda-forge\n",
            "    setuptools-67.1.0          |     pyhd8ed1ab_0         562 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        26.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge None\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu None\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4 None\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.12.7-ha878542_0 None\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 None\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 None\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19 None\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19 None\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0 None\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0 None\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000 None\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4 None\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1 None\n",
            "  openssl            conda-forge/linux-64::openssl-3.0.7-h0b41bf4_2 None\n",
            "  pip                conda-forge/noarch::pip-23.0-pyhd8ed1ab_0 None\n",
            "  python             conda-forge/linux-64::python-3.8.16-he550d4f_1_cpython None\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0 None\n",
            "  setuptools         conda-forge/noarch::setuptools-67.1.0-pyhd8ed1ab_0 None\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0 None\n",
            "  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0 None\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "python-3.8.16        | 21.8 MB   | : 100% 1.0/1 [00:02<00:00,  2.39s/it]               \n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 12.59it/s]\n",
            "openssl-3.0.7        | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.77it/s]\n",
            "ld_impl_linux-64-2.4 | 688 KB    | : 100% 1.0/1 [00:00<00:00,  9.76it/s]\n",
            "pip-23.0             | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.38it/s]\n",
            "setuptools-67.1.0    | 562 KB    | : 100% 1.0/1 [00:00<00:00,  4.63it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate paddle_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlepaddle\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f2/af/f80189956df6ddb3a9aafdb97bd4eab281603382cf9e7d91ae9c3ba95590/paddlepaddle-2.4.1-cp38-cp38-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.13\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9c/ee/77768cade9607687fadbcc1dcbb82dba0554154b3aa641f9c17233ffabe8/numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/77/ba/2f29a6b7224b3e81ddb4d755c66d311d7f3e7c97e40a7f6ccb628b118633/Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.0,>=3.1.0\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/88/88/cd55f87e896b82a3aba8e6c0affc077de51f7321cf730622b17ef7b0f69c/protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting paddle-bfloat==0.1.7\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/d7/ba0e1aeec33e20c78af5cf2fdbb7e7cabfe4679557e68759a17c97e03540/paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.5/385.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astor\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (2.28.1)\n",
            "Collecting opt-einsum==3.3.0\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d5/50/83c593b07763e1161326b3b8c6686f0f4b0f24d5526546bee538c89837d6/decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (1.26.13)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2022.9.24)\n",
            "Installing collected packages: paddle-bfloat, six, protobuf, Pillow, numpy, decorator, astor, opt-einsum, paddlepaddle\n",
            "Successfully installed Pillow-9.4.0 astor-0.8.1 decorator-5.1.1 numpy-1.24.2 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddlepaddle-2.4.1 protobuf-3.20.0 six-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddleocr\n",
            "  Downloading paddleocr-2.6.1.2-py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.6/440.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml\n",
            "  Downloading lxml-4.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire>=0.3.0\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting premailer\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting fonttools>=4.24.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper\n",
            "  Downloading pyclipper-1.3.0.post4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (619 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.2/619.2 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python\n",
            "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cython\n",
            "  Downloading Cython-0.29.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imgaug\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting visualdl\n",
            "  Downloading visualdl-2.5.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2docx\n",
            "  Downloading pdf2docx-0.5.6-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb\n",
            "  Downloading lmdb-1.4.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.1/306.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openpyxl\n",
            "  Downloading openpyxl-3.1.0-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely\n",
            "  Downloading shapely-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from paddleocr) (1.24.2)\n",
            "Collecting PyMuPDF<1.21.0\n",
            "  Downloading PyMuPDF-1.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from fire>=0.3.0->paddleocr) (1.16.0)\n",
            "Collecting termcolor\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio\n",
            "  Downloading imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/site-packages (from imgaug->paddleocr) (9.4.0)\n",
            "Collecting networkx>=2.2\n",
            "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2023.2.3-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.1/215.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting et-xmlfile\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting cssselect\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cssutils\n",
            "  Downloading cssutils-2.6.0-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from premailer->paddleocr) (2.28.1)\n",
            "Collecting cachetools\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce_python_sdk-0.8.79-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.0 in /usr/local/lib/python3.8/site-packages (from visualdl->paddleocr) (3.20.0)\n",
            "Collecting x2paddle\n",
            "  Downloading x2paddle-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.1/319.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-3.17.1-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-Babel>=3.0.0\n",
            "  Downloading flask_babel-3.0.1-py3-none-any.whl (11 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask>=1.1.1\n",
            "  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tritonclient[all]\n",
            "  Downloading tritonclient-2.30.0-py3-none-manylinux1_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.6.0\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting importlib-metadata>=3.6.0\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting Jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Werkzeug>=2.2.2\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=8.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Babel<3.0.0,>=2.11.0\n",
            "  Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz<2023.0,>=2022.7\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.6.2.1\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting protobuf>=3.11.0\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future>=0.6.0\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting markdown-it-py[linkify,plugins]>=2.0.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting altair>=4.2.0\n",
            "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic\n",
            "  Downloading pydantic-1.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting markupsafe\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson\n",
            "  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->premailer->paddleocr) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->premailer->paddleocr) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->premailer->paddleocr) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->premailer->paddleocr) (1.26.13)\n",
            "Collecting python-rapidjson>=0.9.1\n",
            "  Downloading python_rapidjson-1.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.41.0\n",
            "  Downloading grpcio-1.51.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting geventhttpclient<=2.0.2,>=1.4.4\n",
            "  Downloading geventhttpclient-2.0.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting jsonschema>=3.0\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->visualdl->paddleocr) (0.12.0)\n",
            "Collecting gevent>=0.13\n",
            "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading zipp-3.12.1-py3-none-any.whl (6.7 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette==0.22.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->paddleocr) (65.5.1)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting greenlet>=2.0.0\n",
            "  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.5/618.5 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources>=1.4.0\n",
            "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Building wheels for collected packages: fire, python-docx, future, ffmpy, python-multipart\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=9590528d7fe7ceeff94ca4b9486b1120ed803d4f0d837bd6af9e5fa4f072f7cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/86/45/88e8603bd3b1a9bff9d02d820c7431c47ad032865632657bb9\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184490 sha256=779907dc98146ec0a75c5e5bcac8fbd23661c62a15e18e54813037b5acbcd85d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/08/226d68e153dd4ec32713fbac0b1800b1311ff0adbc8eab3c06\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=dc8a62877c98653e9fe96accfd44c8529a50d7fb4f3d5a86137aba895536e555\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/db/41/71a0e5d071a14e716cc11bb021a9caa8f76ec337eca071487e\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=ef7d5a79a71f8ffba0379ffe116b762d5029dbb12346a8dd09e70eee40f356ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/a7/3e/a6b4408a53b4de8176071a885ed909562c2e4e9422ef7622fe\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31670 sha256=0df019e349492d436dc45fc6701a3b9fa1669fe471fa8f530c0d2377d8318fd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/98/35/8ff0b7838d6311008ca83f447b67df38d2d40f55aedadaf332\n",
            "Successfully built fire python-docx future ffmpy python-multipart\n",
            "Installing collected packages: rfc3986, rarfile, pytz, pydub, pyclipper, mpmath, lmdb, ffmpy, brotli, zope.interface, zope.event, zipp, websockets, uc-micro-py, typing-extensions, tqdm, tifffile, termcolor, sympy, soupsieve, sniffio, shapely, scipy, rapidfuzz, pyyaml, PyWavelets, python-rapidjson, python-multipart, python-dateutil, pyrsistent, pyparsing, PyMuPDF, pycryptodome, psutil, protobuf, pkgutil-resolve-name, packaging, orjson, opencv-python, opencv-contrib-python, networkx, multidict, mdurl, markupsafe, lxml, kiwisolver, itsdangerous, imageio, h11, grpcio, greenlet, future, fsspec, frozenlist, fonttools, et-xmlfile, entrypoints, dill, cython, cycler, cssutils, cssselect, contourpy, click, cachetools, Babel, attrs, attrdict, async-timeout, aiofiles, yarl, x2paddle, Werkzeug, uvicorn, tritonclient, scikit-image, python-docx, pydantic, premailer, pandas, openpyxl, onnx, multiprocess, matplotlib, markdown-it-py, linkify-it-py, Jinja2, importlib-resources, importlib-metadata, gevent, fire, beautifulsoup4, bce-python-sdk, anyio, aiosignal, starlette, pdf2docx, mdit-py-plugins, jsonschema, imgaug, httpcore, geventhttpclient, flask, aiohttp, httpx, Flask-Babel, fastapi, altair, gradio, visualdl, paddleocr\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "paddlepaddle 2.4.1 requires protobuf<=3.20.0,>=3.1.0, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.11.0 Flask-Babel-3.0.1 Jinja2-3.1.2 PyMuPDF-1.20.2 PyWavelets-1.4.1 Werkzeug-2.2.2 aiofiles-22.1.0 aiohttp-3.8.3 aiosignal-1.3.1 altair-4.2.2 anyio-3.6.2 async-timeout-4.0.2 attrdict-2.0.1 attrs-22.2.0 bce-python-sdk-0.8.79 beautifulsoup4-4.11.2 brotli-1.0.9 cachetools-5.3.0 click-8.1.3 contourpy-1.0.7 cssselect-1.2.0 cssutils-2.6.0 cycler-0.11.0 cython-0.29.33 dill-0.3.6 entrypoints-0.4 et-xmlfile-1.1.0 fastapi-0.89.1 ffmpy-0.3.0 fire-0.5.0 flask-2.2.2 fonttools-4.38.0 frozenlist-1.3.3 fsspec-2023.1.0 future-0.18.3 gevent-22.10.2 geventhttpclient-2.0.2 gradio-3.17.1 greenlet-2.0.2 grpcio-1.51.1 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 imageio-2.25.0 imgaug-0.4.0 importlib-metadata-6.0.0 importlib-resources-5.10.2 itsdangerous-2.1.2 jsonschema-4.17.3 kiwisolver-1.4.4 linkify-it-py-1.0.3 lmdb-1.4.0 lxml-4.9.2 markdown-it-py-2.1.0 markupsafe-2.1.2 matplotlib-3.6.3 mdit-py-plugins-0.3.3 mdurl-0.1.2 mpmath-1.2.1 multidict-6.0.4 multiprocess-0.70.14 networkx-3.0 onnx-1.13.0 opencv-contrib-python-4.7.0.68 opencv-python-4.7.0.68 openpyxl-3.1.0 orjson-3.8.5 packaging-23.0 paddleocr-2.6.1.2 pandas-1.5.3 pdf2docx-0.5.6 pkgutil-resolve-name-1.3.10 premailer-3.10.0 protobuf-3.20.3 psutil-5.9.4 pyclipper-1.3.0.post4 pycryptodome-3.17 pydantic-1.10.4 pydub-0.25.1 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-docx-0.8.11 python-multipart-0.0.5 python-rapidjson-1.9 pytz-2022.7.1 pyyaml-6.0 rapidfuzz-2.13.7 rarfile-4.0 rfc3986-1.5.0 scikit-image-0.19.3 scipy-1.10.0 shapely-2.0.1 sniffio-1.3.0 soupsieve-2.3.2.post1 starlette-0.22.0 sympy-1.11.1 termcolor-2.2.0 tifffile-2023.2.3 tqdm-4.64.1 tritonclient-2.30.0 typing-extensions-4.4.0 uc-micro-py-1.0.1 uvicorn-0.20.0 visualdl-2.5.0 websockets-10.4 x2paddle-1.4.0 yarl-1.8.2 zipp-3.12.1 zope.event-4.6 zope.interface-5.5.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.8/site-packages (2.4.1)\n",
            "Collecting protobuf<=3.20.0,>=3.1.0\n",
            "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (2.28.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (1.16.0)\n",
            "Requirement already satisfied: paddle-bfloat==0.1.7 in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (0.1.7)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (5.1.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (1.24.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/site-packages (from paddlepaddle) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (1.26.13)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colorthief\n",
            "  Downloading colorthief-0.2.1-py2.py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/site-packages (from colorthief) (9.4.0)\n",
            "Installing collected packages: colorthief\n",
            "Successfully installed colorthief-0.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neurokit2\n",
            "  Downloading neurokit2-0.2.2-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (from neurokit2) (3.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from neurokit2) (1.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from neurokit2) (1.24.2)\n",
            "Collecting scikit-learn>=1.0.0\n",
            "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from neurokit2) (1.5.3)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->neurokit2) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas->neurokit2) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn, neurokit2\n",
            "Successfully installed joblib-1.2.0 neurokit2-0.2.2 scikit-learn-1.2.1 threadpoolctl-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deskew\n",
            "  Downloading deskew-1.3.3-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from deskew) (1.24.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/site-packages (from deskew) (0.19.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (2.25.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (1.10.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (2023.2.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (23.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/site-packages (from scikit-image->deskew) (3.0)\n",
            "Installing collected packages: deskew\n",
            "Successfully installed deskew-1.3.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.51.1)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.24.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow) (65.5.1)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting libclang>=13.0.0\n",
            "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.12.1)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, wrapt, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, keras, h5py, google-pasta, gast, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 h5py-3.8.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 wrapt-1.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
            "  from .collection import imread_collection_wrapper\n",
            "/usr/local/lib/python3.8/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.00M/4.00M [00:17<00:00, 233kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv3_rec_infer/en_PP-OCRv3_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.96M/9.96M [00:26<00:00, 376kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.19M/2.19M [00:16<00:00, 137kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023/02/07 19:36:57] ppocr DEBUG: Namespace(alpha=1.0, benchmark=False, beta=1.0, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=True, fourier_degree=5, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv3', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/usr/local/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv3_rec_infer', recovery=False, save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eff_net'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 7 (delta 1), reused 7 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), 689 bytes | 344.00 KiB/s, done.\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.21.6\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda create --name paddle_env python=3.8 --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n",
        "!source activate paddle_env\n",
        "!python -m pip install paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
        "!pip install paddleocr --upgrade\n",
        "!pip install paddlepaddle\n",
        "!pip install colorthief\n",
        "!pip install neurokit2\n",
        "!pip install deskew\n",
        "!pip install tensorflow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from deskew import determine_skew\n",
        "from typing import Tuple, Union\n",
        "from colorthief import ColorThief\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "import neurokit2 as nk\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "# Importing models\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en', enable_mkldnn=True)\n",
        "!git clone https://github.com/ramsundar-tanikella/eff_net \n",
        "segmentationModel = tf.keras.models.load_model('/content/eff_net/efficientnetB4_2.h5')\n",
        "segmentationModel.predict(np.zeros((1,380,380,3))) # To run it once so that weights get loaded into memory\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BRBzoGu-WcA"
      },
      "source": [
        "#Skew Correction, Padding, Segmentation and cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKjNVMnT-VTB"
      },
      "outputs": [],
      "source": [
        "# Skew Correction \n",
        "\n",
        "def deskewImage(image):\n",
        "    imageGrayscale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    angle = determine_skew(imageGrayscale)\n",
        "    deskewedImage = rotate(image, angle)\n",
        "    deskewedImage = cv2.resize(deskewedImage, (1280,720))\n",
        "    return deskewedImage\n",
        "\n",
        "def rotate(image, angle):\n",
        "    old_width, old_height = image.shape[:2]\n",
        "    angle_radian = math.radians(angle)\n",
        "    width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
        "    height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
        "\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    rot_mat[1, 2] += (width - old_width) / 2\n",
        "    rot_mat[0, 2] += (height - old_height) / 2\n",
        "    return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=(255,255,255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1821v2QD-fjq"
      },
      "source": [
        "**Reason for padding -** \n",
        "\n",
        "The images used for training the  model for segmentation are atleast 270 pixels away from the vertical edges. So, just for the model to work well on images which are very close to the vertical edges we have padded the image by 600 pixels horizontally(padding of 300 on each edge). As the images as padded by 600 pixels horizontally ,just to maintain the aspect ratio of the images we have padded the image by 338 pixels vertically (padding of 169 on each edge)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUsAxgnW-hHh"
      },
      "outputs": [],
      "source": [
        "# Padding\n",
        "\n",
        "def pad(img):\n",
        "    height, width = img.shape[:2]\n",
        "    new_width = width + 600\n",
        "    new_height = height + 338\n",
        "    new_img = 255 * np.ones((new_height, new_width, 3), dtype=\"uint8\")\n",
        "    start_row = 169\n",
        "    start_col = 300\n",
        "    new_img[start_row:start_row + height, start_col:start_col + width, :] = img\n",
        "    original_size = (1280, 720)\n",
        "    img_resized = cv2.resize(new_img, original_size, interpolation=cv2.INTER_CUBIC)\n",
        "    return img_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXMeGh1G-p4D"
      },
      "outputs": [],
      "source": [
        "# Main Segmentation function that will be called in inference()\n",
        "\n",
        "def segmentation(imagepath):\n",
        "    image = processImage(imagepath)\n",
        "    image = deskewImage(image)\n",
        "    image = pad(image)\n",
        "    coordinates = giveCoordinates(image)\n",
        "    croppedImage = croppingSegmentatedImages(coordinates, image)\n",
        "    return croppedImage\n",
        "\n",
        "def processImage(imagePath):\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "def giveCoordinates(image):\n",
        "    image = cv2.resize(image, (380, 380))\n",
        "    expandedImage = np.expand_dims(image, axis=0)\n",
        "    coordinates = segmentationModel.predict(expandedImage)\n",
        "    coordinates = coordinates[0].astype(int)\n",
        "    return coordinates\n",
        "\n",
        "def croppingSegmentatedImages(coordinates, image):\n",
        "    x1, y1, x2, y2, x3, y3, x4, y4 = coordinates\n",
        "    top_left_x = min([x1,x2,x3,x4])\n",
        "    top_left_y = min([y1,y2,y3,y4]) \n",
        "    bot_right_x = max([x1,x2,x3,x4]) + 20\n",
        "    bot_right_y = max([y1,y2,y3,y4]) \n",
        "    \n",
        "    height, width = image.shape[:2]\n",
        "    new_width = width + 20\n",
        "    new_height = height\n",
        "    new_img = 255 * np.ones((new_height, new_width, 3), dtype=\"uint8\")\n",
        "    start_row = 0\n",
        "    start_col = 10\n",
        "    new_img[start_row:start_row + height, start_col:start_col + width, :] = image\n",
        "\n",
        "    croppedImage = new_img[top_left_y:bot_right_y, top_left_x:bot_right_x]\n",
        "    croppedImage = cv2.resize(croppedImage, (1280, 720))\n",
        "    return croppedImage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BaJCNbT2ksJ"
      },
      "source": [
        "#Basic Functions\n",
        "Used to perform basic functions like displaying images, sorting coordinates, normalizing the image, string to integer conversion, whether string is integer or not etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L0MCrlC2m8o"
      },
      "outputs": [],
      "source": [
        "def removeAllText(result):\n",
        "  bin = list()\n",
        "  for x in result[0]:\n",
        "    if(x[1][0].isdigit() == False ):\n",
        "      bin.append(x)\n",
        "  for x in bin:\n",
        "    result[0].remove(x)\n",
        "      \n",
        "def removeBinElements(result, ignore_bin2, ignore_bin):\n",
        "  bin = list()\n",
        "  for x in ignore_bin2:\n",
        "    if x in result[0] and x[1][0] in ignore_bin:\n",
        "      # print(x[1][0])\n",
        "      bin.append(x[1][0])\n",
        "      result[0].remove(x)\n",
        "  ignore_bin2.clear()\n",
        "  for y in bin:\n",
        "    ignore_bin.remove(y)\n",
        "\n",
        "#Function to give font size\n",
        "def boxSize(A):\n",
        "  y = ([A[0][1], A[1][1], A[2][1], A[3][1]])\n",
        "  y.sort()\n",
        "  return y[3] - y[0]\n",
        "\n",
        "#Taking the largest pixel in the box\n",
        "def normalize(result):\n",
        "  mx = 1\n",
        "  for x in result[0]:\n",
        "    if x[1][0].isdigit():\n",
        "      mx = max( mx , boxSize(x[0]) )\n",
        "  return mx\n",
        "\n",
        "#A function to delete bounding boxes less than a particular threshold value\n",
        "def threshDelete(thresh, mx, result):\n",
        "  small_vals = list()\n",
        "  for x in result[0]:\n",
        "    if x[1][0].isdigit():\n",
        "      if float(boxSize(x[0])/mx) <= thresh :\n",
        "        small_vals.append(x)\n",
        "  for y in small_vals:\n",
        "    result[0].remove(y)\n",
        "\n",
        "#String to integer\n",
        "def stoi(string):\n",
        "  x = 0\n",
        "  string = str(string)\n",
        "  for i in string :\n",
        "    if i.isdigit():\n",
        "      x = x * 10 + int( i )\n",
        "  return x \n",
        "\n",
        "#Checks whether if particular element in the list is present in the string or not\n",
        "def checkIfPresent(string, list):\n",
        "  for y in list:\n",
        "    if y in string.lower():\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def isNumber1(string):\n",
        "    for a in string:\n",
        "      if(a.isalpha() == True and a != 'L'):\n",
        "        return False\n",
        "    return True \n",
        "\n",
        "#Ignoring some known character anomalies like '(',')','/' etc\n",
        "def isNumber2 (string):\n",
        "    for a in string:\n",
        "        if((a.isalpha() == True)|(((a != '[')&(a != ']'))&(a != ')')&(a != '(')&(a != '/')&(a != ' ')&(a.isdigit() == False))):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "#Finding the smallest two numbers of given 3 numbers\n",
        "def find_smallest_two(a, b, c):\n",
        "    if a <= b and a <= c:\n",
        "        return a, min(b, c)\n",
        "    elif b <= a and b <= c:\n",
        "        return b, min(a, c)\n",
        "    else:\n",
        "        return [c, min(a, b)]\n",
        "\n",
        "#formats the data\n",
        "#ignoring known keywords like \"ADULT\"\n",
        "#removing / in bp and ( ) in map\n",
        "#evaluating sys and dia from bp\n",
        "#checking whether map is in acceptable range of sys and dia\n",
        "#removing erraneous characters from hr\n",
        "def clear(icu_res):\n",
        "  if \"map\" in icu_res:\n",
        "    string = str(icu_res[\"map\"])\n",
        "    if \"adu\" in string.lower():\n",
        "      pos = string.find(\"adu\") - 3\n",
        "      string = string[0:pos - 1]\n",
        "      if string == \"BO\" or string == \"8O\" or string == \"B0\":\n",
        "        string = \"80\"\n",
        "    icu_res[\"map\"] = stoi(string)\n",
        "  if \"bp\" in icu_res:\n",
        "    if \"/\" in icu_res[\"bp\"]:\n",
        "      string = icu_res[\"bp\"]\n",
        "      pos = string.find(\"/\")\n",
        "      pos2 = string.find(\"/\",pos)\n",
        "      if pos2 != -1:\n",
        "        string = string[0:pos] + \"/\" + string[pos2+1:]\n",
        "      res = \"\"\n",
        "      for c in string:\n",
        "        if c.isdigit() or c == '/':\n",
        "          res += c\n",
        "    else:\n",
        "      string = icu_res[\"bp\"]\n",
        "      if( len(string) > 5 ):\n",
        "        string = string[0:3] + \"/\" + string[4:]\n",
        "      else:\n",
        "        string = string[0:3] + \"/\" + string[3:]\n",
        "      res = \"\"\n",
        "      for c in string:\n",
        "        if c.isdigit() or c == '/':\n",
        "            res += c\n",
        "    del icu_res[\"bp\"]\n",
        "    lst = res.split(\"/\")\n",
        "    if len(lst) > 0:\n",
        "      icu_res[\"sys\"] = lst[0]\n",
        "    if len(lst) > 1:\n",
        "      x = lst[1][0:3]\n",
        "      if len(x) > 2 and x[0] >= '6':\n",
        "        x = x[0:2]\n",
        "      if len(x) > 2 and x[0] >= '2':\n",
        "        x = x[1:]\n",
        "      icu_res[\"dia\"] = x \n",
        "  if \"sys\" in icu_res and \"dia\" in icu_res :\n",
        "    if( stoi( str(icu_res[\"sys\"])) < stoi(str(icu_res[\"dia\"]))  ):\n",
        "        temp = icu_res[\"sys\"]\n",
        "        icu_res[\"sys\"] = icu_res[\"dia\"]\n",
        "        icu_res[\"dia\"] = temp \n",
        "  if \"sys\" in icu_res and \"dia\" in icu_res and \"map\" in icu_res and icu_res[\"sys\"] != \"\" and icu_res[\"dia\"] != \"\":\n",
        "    ideal = int( int(icu_res[\"sys\"])/3 + 2*int(icu_res[\"dia\"])/3 )\n",
        "    if icu_res[\"map\"] < ideal - 13 or icu_res[\"map\"] > ideal + 13 :\n",
        "      icu_res[\"map\"] = str(ideal)\n",
        "  if \"map\" not in icu_res or icu_res[\"map\"] == \"\" :\n",
        "    icu_res[\"map\"] = str(int( int(icu_res[\"sys\"])/3 + 2*int(icu_res[\"dia\"])/3 ))\n",
        "  if \"hr\" in icu_res:\n",
        "    valuex = str(icu_res[\"hr\"])\n",
        "    if len( valuex ) > 2 and valuex[0] > '2' :\n",
        "      icu_res[\"hr\"] = valuex[0:2]\n",
        "    else:\n",
        "      icu_res[\"hr\"] = valuex[0:3]\n",
        "  if 'spO2' in icu_res:\n",
        "    if stoi(icu_res['spO2']) < 50:\n",
        "      icu_res['spO2'] = ''\n",
        "  if 'rr' in icu_res:\n",
        "    if stoi(icu_res['rr']) > 50:\n",
        "      icu_res['rr'] = ''\n",
        "\n",
        "# In this function we make all the desired values to match with the sample format \n",
        "def capitalise_keys (icu_res):\n",
        "  if \"hr\" in icu_res:\n",
        "    icu_res[\"HR\"] = str(icu_res[\"hr\"])\n",
        "    del icu_res[\"hr\"]\n",
        "  else:\n",
        "    icu_res[\"HR\"] = \"\"\n",
        "  if \"spo2\" in icu_res:\n",
        "    icu_res[\"SPO2\"] = str(icu_res[\"spo2\"])\n",
        "    del icu_res[\"spo2\"]\n",
        "  else:\n",
        "    icu_res[\"SPO2\"] = \"\"\n",
        "  if \"rr\" in icu_res:\n",
        "    icu_res[\"RR\"] = str(icu_res[\"rr\"])\n",
        "    del icu_res[\"rr\" ]\n",
        "  else:\n",
        "    icu_res[\"RR\"] = \"\"\n",
        "  if \"sys\" in icu_res:\n",
        "    icu_res[\"SBP\"] = str(icu_res[\"sys\"])\n",
        "    del icu_res[\"sys\"]\n",
        "  else:\n",
        "    icu_res[\"SBP\"] = \"\"\n",
        "  if \"dia\" in icu_res:\n",
        "    icu_res[\"DBP\"] = str(icu_res[\"dia\"])\n",
        "    del icu_res[\"dia\"]\n",
        "  else:\n",
        "    icu_res[\"DBP\"] = \"\"\n",
        "  if \"map\" in icu_res:\n",
        "    if stoi(icu_res[\"map\"]) == 0:\n",
        "      icu_res[\"map\"] = \"\"\n",
        "    icu_res[\"MAP\"] = str(icu_res[\"map\"])\n",
        "    del icu_res[\"map\"]\n",
        "  else:\n",
        "    icu_res[\"MAP\"] = \"\"\n",
        "  if \"map_confid\" in icu_res:\n",
        "    del icu_res[\"map_confid\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-DM7cZsyn2C"
      },
      "source": [
        "#Geometric Functions\n",
        "Functions used to find out geometric details of image.\n",
        "Example,\n",
        "- Distance between two segments\n",
        "- Whether two segments intersect in a plane or not\n",
        "- Distance between points and segments\n",
        "- Shortest distance between two Bounding Boxes\n",
        "- Find 3 closest Bounding boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "075mYR4FywpR"
      },
      "outputs": [],
      "source": [
        "#Shortest Distance between two line segments \n",
        "def segments_distance(x11, y11, x12, y12, x21, y21, x22, y22):\n",
        "  \"\"\" distance between two segments in the plane:\n",
        "      one segment is (x11, y11) to (x12, y12)\n",
        "      the other is   (x21, y21) to (x22, y22)\n",
        "  \"\"\"\n",
        "  if segments_intersect(x11, y11, x12, y12, x21, y21, x22, y22): return 0\n",
        "  # try each of the 4 vertices w/the other segment\n",
        "  distances = []\n",
        "  distances.append(point_segment_distance(x11, y11, x21, y21, x22, y22))\n",
        "  distances.append(point_segment_distance(x12, y12, x21, y21, x22, y22))\n",
        "  distances.append(point_segment_distance(x21, y21, x11, y11, x12, y12))\n",
        "  distances.append(point_segment_distance(x22, y22, x11, y11, x12, y12))\n",
        "  return min(distances)\n",
        "\n",
        "#Check whether two segments intersect or not\n",
        "def segments_intersect(x11, y11, x12, y12, x21, y21, x22, y22):\n",
        "  \"\"\" whether two segments in the plane intersect:\n",
        "      one segment is (x11, y11) to (x12, y12)\n",
        "      the other is   (x21, y21) to (x22, y22)\n",
        "  \"\"\"\n",
        "  dx1 = x12 - x11\n",
        "  dy1 = y12 - y11\n",
        "  dx2 = x22 - x21\n",
        "  dy2 = y22 - y21\n",
        "  delta = dx2 * dy1 - dy2 * dx1\n",
        "  if delta == 0: return False  # parallel segments\n",
        "  s = (dx1 * (y21 - y11) + dy1 * (x11 - x21)) / delta\n",
        "  t = (dx2 * (y11 - y21) + dy2 * (x21 - x11)) / (-delta)\n",
        "  return (0 <= s <= 1) and (0 <= t <= 1)\n",
        "\n",
        "#Shortest distance of a point from a segment\n",
        "def point_segment_distance(px, py, x1, y1, x2, y2):\n",
        "  dx = x2 - x1\n",
        "  dy = y2 - y1\n",
        "  if dx == dy == 0:  # the segment's just a point\n",
        "    return math.hypot(px - x1, py - y1)\n",
        "\n",
        "  # Calculate the t that minimizes the distance.\n",
        "  t = ((px - x1) * dx + (py - y1) * dy) / (dx * dx + dy * dy)\n",
        "\n",
        "  # See if this represents one of the segment's\n",
        "  # end points or a point in the middle.\n",
        "  if t < 0:\n",
        "    dx = px - x1\n",
        "    dy = py - y1\n",
        "  elif t > 1:\n",
        "    dx = px - x2\n",
        "    dy = py - y2\n",
        "  else:\n",
        "    near_x = x1 + t * dx\n",
        "    near_y = y1 + t * dy\n",
        "    dx = px - near_x\n",
        "    dy = py - near_y\n",
        "\n",
        "  return math.hypot(dx, dy)\n",
        "\n",
        "#Shortest distance between two bounding boxes\n",
        "def shortest_distance_between_two_bounding_boxes (A, B):\n",
        "  ans = -1\n",
        "  for i in range(4):\n",
        "      X1 = A[i]\n",
        "      Y1 = A[ ( i + 1 )%4 ]\n",
        "      a = np.array([X1[0], X1[1]])\n",
        "      b = np.array([Y1[0], Y1[1]])\n",
        "      for j in range(4):\n",
        "          X2 = B[j]\n",
        "          Y2 = B[(j+1)%4]\n",
        "          c = np.array([X2[0], X2[1]])\n",
        "          d = np.array([Y2[0], Y2[1]])\n",
        "          dist = segments_distance( a[0] , a[1] , b[0] , b[1] , c[0] , c[1] , d[0] , d[1] );\n",
        "          if (( ans == -1 )|(ans > dist )):\n",
        "              ans = dist\n",
        "  return ans\n",
        "\n",
        "#Finding the shortest distance between given three bounding boxes\n",
        "def find3closest (A, B, C):\n",
        "  x = shortest_distance_between_two_bounding_boxes( A , B )\n",
        "  y = shortest_distance_between_two_bounding_boxes( A , C )\n",
        "  z = shortest_distance_between_two_bounding_boxes( B , C )\n",
        "  res = [ x , y , z ]\n",
        "  res.sort()\n",
        "  return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWEMg-F36iA"
      },
      "source": [
        "#***Detecting Specific Values***\n",
        "\n",
        "Here we have the following functions to detect the respective vitals\n",
        "- solvebpfirst1 : to find BP\n",
        "- solvebpfirst2 : to find BP and MAP using Keywords\n",
        "- solveMapnotfound : to find out MAP if not found till now\n",
        "- solvebplast   : last attempt to find the BP value using ditance logic\n",
        "- detect_rr : Detects RR based on RR keyword\n",
        "- detect_hr : Detects HR based on keyword\n",
        "- detect_hr_color : Checks the color of HR and if it is in green range then we accept the value as HR.\n",
        "- detect_spo2 : Detects SPO2 based on keywords of spo2 \n",
        "- check_hr_color_range : checks the range of green color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5QJEHr6383o"
      },
      "outputs": [],
      "source": [
        "#First logic to find the BP \n",
        "def solvebpfirst1(thresh, icu_res, result, maxElSize, ignore_bin2, ignore_bin):\n",
        "  # print(\"bp1\")\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  bp = str()\n",
        "  mp = str()\n",
        "  map_bin = list()\n",
        "  for x in result[0]:\n",
        "      if isNumber2(x[1][0]):\n",
        "          #If length of numeric string is greater than 7 then we find BP and MAP\n",
        "          if( len(x[1][0]) > 7 ):\n",
        "            #Check whether opening bracket is present \n",
        "            ans = x[1][0]\n",
        "            if \"(\" in x[1][0]:\n",
        "                ans = x[1][0].split(\"(\")\n",
        "                bp = ans[0]\n",
        "                mp = ans[1]\n",
        "                ignore_bin2.append(x)\n",
        "            else:\n",
        "                bp = ans[0:5]\n",
        "                mp = ans[5:]\n",
        "                ignore_bin2.append(x)\n",
        "          #Checking if the length is >=5 and <7 and try to detect '/' to find BP\n",
        "          elif( len(x[1][0]) >= 5 )&( \"/\" in x[1][0] )and( boxSize(x[0]) >= 0.4*maxElSize ):\n",
        "              bp = x[1][0]\n",
        "              ignore_bin2.append(x);\n",
        "              for y in result[0]:\n",
        "                  #Trying to find MAP using opening or closing bracket and confidence of the text detector\n",
        "                  if (y != x)&( isNumber2( y[1][0] )) :\n",
        "                      if( \"(\" in y[1][0] or \")\" in y[1][0] or \"[\" in y[1][0] or \"]\" in y[1][0]):\n",
        "                          if( \"map_confid\" not in icu_res or icu_res[\"map_confid\"] < y[1][1] ):\n",
        "                            mp = y[1][0]\n",
        "                            icu_res[\"map_confid\"] = y[1][1]\n",
        "                            map_bin = y\n",
        "                      #If the shortest distance between BP and number is less than a threshold then we find MAP\n",
        "                      if( shortest_distance_between_two_bounding_boxes( x[0] , y[0] ) < 40 ):\n",
        "                          if( \"map_confid\" not in icu_res or int(icu_res[\"map_confid\"]) < 60 ):\n",
        "                            mp = y[1][0]\n",
        "                            icu_res[\"map_confid\"] = y[1][1]\n",
        "                            map_bin = y\n",
        "          #Assuming / is not detetcted\n",
        "          elif( len(x[1][0]) >= 5 and boxSize(x[0]) >= 0.4*maxElSize ):\n",
        "            ignore_bin.append(x)\n",
        "            return [ x[1][0] , \"\" ]\n",
        "          #For length less than equal to 4 and / is detected\n",
        "          #If '/' is detected it is probably SysBP or DiaBP\n",
        "          elif( \"/\" in x and len(x) < 4 and boxSize(x[0]) >= 0.4*maxElSize ):\n",
        "            bp = x[1][0]\n",
        "            distances = list()\n",
        "            for y in result[0]:\n",
        "              if (x != y)&(isNumber2(y[1][0])):\n",
        "                #Trying to find two closest numeric bounding boxes and sorting it. \n",
        "                distances.append( ( shortest_distance_between_two_bounding_boxes( x[0] , y[0] ) , y  ))\n",
        "            distances.sort()\n",
        "            #Pressure is the value of bounding boxes satisfying the threshold\n",
        "            pressure = list()\n",
        "            for i in range(3):\n",
        "              if( distances[i][0] <= thresh ):\n",
        "                #Checking if there are bounding boxes which are satisfying our threshold\n",
        "                pressure.append( ( stoi(distances[i][1][1][0]) , distances[i][1] ) )\n",
        "              else:\n",
        "                break\n",
        "            pressure.sort()\n",
        "            #Finding MAP and SysBP/DiaBP from pressure\n",
        "            if( len( pressure ) >= 1 ):\n",
        "              rs = [ stoi(bp) , stoi(pressure[0][0]) ]\n",
        "              rs.sort()\n",
        "              bp = str(rs[1]) + \"/\" + str(rs[0])\n",
        "              map_bin = [ x , pressure[0][1] ]\n",
        "\n",
        "      if bp != \"\":\n",
        "        break\n",
        "  #Ignoring found values for further ananlysis\n",
        "  if len(map_bin) > 0:\n",
        "    ignore_bin2.append(map_bin)\n",
        "  return [ bp , mp ]\n",
        "\n",
        "#Second attempt to find BP and MAP using Keyword recognition\n",
        "def solvebpfirst2(thresh, thresh1, result, ignore_bin2, ignore_bin):\n",
        "  # print(\"bp2\")\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  bp1 = str()\n",
        "  bp2 = str()\n",
        "  mp = str()\n",
        "  bp_bin = list()\n",
        "  for i in range(len(result[0])-1,0,-1):\n",
        "    x = result[0][i]\n",
        "    #Checking whether any of the following keyword is present in the string \n",
        "    if checkIfPresent(x[1][0] , [ 'sys' , '5y5' , '5u5' , 'dia' , 'mmhg' , 'winhg','nibp', 'nbp']):\n",
        "      distances = list()\n",
        "      for y in result[0]:\n",
        "        if isNumber2( y[1][0] ) :\n",
        "          #Finding the closest numeric bounding box to the keyword \n",
        "          distances.append( ( shortest_distance_between_two_bounding_boxes( x[0] , y[0] ) , y  ))\n",
        "      distances.sort()\n",
        "      distances2 = list()\n",
        "      #Whether the nearest number is less farther than the threshold  \n",
        "      if distances[0][0] < thresh:\n",
        "        #Finding Two closest numbers near to the number detected closest to the keyword\n",
        "        for z in result[0]:\n",
        "          if isNumber2( z[1][0] ) and ( z != distances[0][1] ) :\n",
        "            distances2.append( ( shortest_distance_between_two_bounding_boxes( z[0] , distances[0][1][0] ) , z ) )\n",
        "        distances2.sort()\n",
        "        pressure = list()\n",
        "        #Finding two closest numbers\n",
        "        for i in range(2):\n",
        "          if i == len(distances2):\n",
        "            break;\n",
        "          if( distances2[i][0] <= thresh1 ):\n",
        "            pressure.append(( stoi(distances2[i][1][1][0]) , distances2[i][1] ))\n",
        "          else:\n",
        "            break\n",
        "        pressure.append(( stoi(distances[0][1][1][0]) , distances[0][1] ))\n",
        "        pressure.sort()\n",
        "        #Detecting BP and Map from this by value of sys>Map>dia\n",
        "        if( len(pressure) == 1 ):\n",
        "          bp2 = str(pressure[0][0])\n",
        "          bp_bin = [ pressure[0][1] ]\n",
        "        elif( len(pressure) == 2 ):\n",
        "          bp2 = str(pressure[0][0])\n",
        "          bp1 = str(pressure[1][0])\n",
        "          bp_bin = [ pressure[0][1] , pressure[1][1] ]\n",
        "        elif( len(pressure) > 2 ):\n",
        "          bp2 = str(pressure[0][0])\n",
        "          mp = str(pressure[1])\n",
        "          bp1 = str(pressure[2][0])\n",
        "          bp_bin = [ pressure[0][1] , pressure[1][1] , pressure[2][1] ]\n",
        "  #Ignoring found numbers in further analysis\n",
        "  for x in bp_bin:\n",
        "    ignore_bin2.append(x)\n",
        "  return [bp1,bp2,mp]\n",
        "\n",
        "\n",
        "\n",
        "# CHECK FROM HERE\n",
        "\n",
        "\n",
        "\n",
        "#Trying to find MAP first using brackets\n",
        "def solveMapNotFound (icu_res, thresh, thresh1, result, ignore_bin2, ignore_bin):\n",
        "  # print(\"mp not found func\")\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  mp = str()\n",
        "  bp1 = str()\n",
        "  bp2 = str()\n",
        "  bp_bin = list()\n",
        "  #Checking for opening or closing brackets \n",
        "  for x in result[0] :\n",
        "    if ( \"adu\" in x[1][0].lower() )|((isNumber2(x[1][0]))&(( \"(\" in x[1][0] )|( \")\" in x[1][0] )|(\"[\" in x[1][0])|(\"]\" in x[1][0]))):\n",
        "      if( \"map_confid\" not in icu_res or icu_res[\"map_confid\"] < x[1][1] ):\n",
        "      #If MAP not found or confidence of current number identified as MAP better than previous number then we update the MAP value \n",
        "        mp = x[1][0]\n",
        "        distances = list()\n",
        "        for y in result[0]:\n",
        "          if (x != y)&(isNumber2(y[1][0])):\n",
        "            # Finding the closest bounding boxes to the MAP value\n",
        "            distances.append( ( shortest_distance_between_two_bounding_boxes( x[0] , y[0] ) , y  ))\n",
        "        distances.sort()\n",
        "        pressure = list()\n",
        "        # Checking whether the numbers are less than a threshold  \n",
        "        for i in range(3):\n",
        "          if i == len(distances):\n",
        "            break;\n",
        "          if( distances[i][0] <= thresh ):\n",
        "            pressure.append( ( stoi(distances[i][1][1][0]) , distances[i][1] ) )\n",
        "          else:\n",
        "            break\n",
        "        pressure.sort()\n",
        "        # Evaluating BP from that \n",
        "        if( len( pressure ) == 1 ):\n",
        "          bp2 = pressure[0][0]\n",
        "          bp_bin = [ x , pressure[0][0] ]\n",
        "        elif( len(pressure) == 2 ):\n",
        "          bp2 = pressure[0][0]\n",
        "          bp1 = pressure[1][0]\n",
        "          bp_bin = [ x , pressure[0][1] , pressure[1][1] ]\n",
        "  # If MAP is still not found then check for the keyword MAP\n",
        "  if mp == \"\":\n",
        "    for x in result[0]:\n",
        "      if checkIfPresent( x[1][0] , [\"map\"] ):\n",
        "        distances = list()\n",
        "        for y in result[0]:\n",
        "          if isNumber2( y[1][0] ) :\n",
        "            # Finding closest numbers to the MAP\n",
        "            distances.append( ( shortest_distance_between_two_bounding_boxes( x[0] , y[0] ) , y  ))\n",
        "        distances.sort()\n",
        "        distances2 = list()\n",
        "        # Checking if distance is less than threshold \n",
        "        if distances[0][0] < thresh:\n",
        "          for z in result[0]:\n",
        "            if isNumber2( z[1][0] ) and ( z != distances[0][1] ) :\n",
        "              # To find two closest numbers to the number found as MAP\n",
        "              distances2.append( ( shortest_distance_between_two_bounding_boxes( z[0] , distances[0][1][0] ) , z ) )\n",
        "          distances2.sort()\n",
        "          pressure = list()\n",
        "          for i in range(2):\n",
        "            if( distances2[i][0] <= thresh1 ):\n",
        "              pressure.append(( distances2[i][1][1][0] , distances2[i][1] ))\n",
        "            else:\n",
        "              break\n",
        "          mp = ( distances[0][1][1][0] )\n",
        "          pressure.sort()\n",
        "          # Evaluating BP from it\n",
        "          if( len( pressure ) == 1 ):\n",
        "            bp_bin = [  distances[0][1] , pressure[0][1] ]\n",
        "            bp2 = pressure[0][0]\n",
        "          elif( len(pressure) == 2 ):\n",
        "            bp2 = pressure[0][0]\n",
        "            bp1 = pressure[1][0]\n",
        "            bp_bin = [  distances[0][1] , pressure[0][1] , pressure[1][1] ]\n",
        "  # Removing found elements from further analysis \n",
        "  for x in bp_bin:\n",
        "    ignore_bin2.append(x)\n",
        "  return [ str(bp1) , str(bp2) , mp ]\n",
        "  # Last Attempt to detect BP\n",
        "  # Finding three closest bounding boxes that are within a threshold\n",
        "def solveBplast( thresh, result, ignore_bin2, ignore_bin):\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  # print(\"solve bplast\")\n",
        "  res = [\"\",\"\",\"\"]\n",
        "  for i in range( len(result[0]) ):\n",
        "    for j in range( i + 1 , len(result[0]) ):\n",
        "      for k in range( j + 1 , len(result[0]) ):\n",
        "        if( isNumber2(result[0][i][1][0]) & isNumber2(result[0][j][1][0]) & isNumber2(result[0][k][1][0]) ):\n",
        "          q = find3closest( result[0][i][0] , result[0][j][0] , result[0][k][0] )\n",
        "          if( q[2] < thresh * 1.8 and q[1] < thresh ):\n",
        "            res = [ stoi(result[0][i][1][0]) , stoi(result[0][j][1][0]) , stoi(result[0][k][1][0]) ]\n",
        "            res.sort()\n",
        "            ignore_bin2.append( result[0][i] )\n",
        "            ignore_bin2.append(result[0][j] )\n",
        "            ignore_bin2.append(result[0][k] )\n",
        "            return [ str(res[0]) , str(res[1]) , str(res[2] ) ]\n",
        "  return res\n",
        "  # Detecting Respiratory Rate\n",
        "def detect_rr(threshold, result, ignore_bin2, ignore_bin):\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  flag_rr = 0\n",
        "  all_num = []\n",
        "  lst = [\"resp\", \"rr\", \"resf\" ]\n",
        "  ans = 0\n",
        "  num = 0\n",
        "  num_no_rr_key = \"\"\n",
        "  rr_bin = list()\n",
        "  rr_bin2 = list()\n",
        "  for idx in range(len(result)):\n",
        "      res = result[idx]\n",
        "      for line in res:\n",
        "        # If a number is in the list within acceptable range of RR i.e, (10,45),saving it for the chance of being RR \n",
        "          if(line[1][0].isdigit()):\n",
        "              all_num.append(line[1][0])\n",
        "              if(int(line[1][0]) > 10 and int(line[1][0]) < 45):\n",
        "                  num_no_rr_key = line[1][0]\n",
        "                  rr_bin2 = line\n",
        "          # To detect if keywords related to RR is present or not\n",
        "          if(checkIfPresent(line[1][0], lst)):\n",
        "              flag_rr = 1\n",
        "              A_cor = line[0]\n",
        "              ans = 1000000\n",
        "              # Find shortest numeric bounding box to that \n",
        "              for line in res:\n",
        "                  if(line[1][0].isdigit() and int(line[1][0]) > 10 and int(line[1][0]) < 45 ):\n",
        "                      B_cor = line[0]\n",
        "                      dis = shortest_distance_between_two_bounding_boxes(A_cor,B_cor)\n",
        "                      if(dis < ans):\n",
        "                          ans = dis\n",
        "                          num = line[1][0]\n",
        "                          rr_bin = line\n",
        "  # If no keyword is found then output the saved numeric value \n",
        "  if(flag_rr == 0):\n",
        "      ignore_bin2.append(rr_bin2)\n",
        "      return num_no_rr_key\n",
        "  #return num\n",
        "  ignore_bin2.append(rr_bin)\n",
        "  # If keyword is found and the number is less farther than the threshold then output the number\n",
        "  if(ans < threshold):\n",
        "      return num\n",
        "  \n",
        "  return -1\n",
        "  # Detecting Heart Rate using Keywords\n",
        "def detect_hr(threshold, result, ignore_bin2, ignore_bin):\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  lst = [\"ecg\", \"hr\", \"pr\", \"bpm\"]\n",
        "  ans = 1000000\n",
        "  num = -1\n",
        "  hr_bin = list()\n",
        "  for idx in range(len(result)):\n",
        "    res = result[idx]\n",
        "    for line1 in res:\n",
        "        # Checking whether Keyword is present \n",
        "      if(checkIfPresent(line1[1][0], lst)):\n",
        "          #flag_rr = 1\n",
        "        A_cor = line1[0]\n",
        "        ans = 1000000\n",
        "        for line2 in res:\n",
        "          if(line2[1][0].isdigit()):\n",
        "            B_cor = line2[0]\n",
        "            # Find the number closest to the keyword\n",
        "            dis = shortest_distance_between_two_bounding_boxes(A_cor,B_cor)\n",
        "            if(dis < ans):\n",
        "              ans = dis\n",
        "              num = line2[1][0]\n",
        "              hr_bin = line2;\n",
        "  # Checking whether the closest number is less farther than the threshold to the keyword \n",
        "  if(ans < threshold):\n",
        "    ignore_bin2.append(hr_bin)\n",
        "    return num\n",
        "  \n",
        "  return -1\n",
        "  # Detecting Heart Rate using standard color and location logic \n",
        "def detect_hr_color(result, ignore_bin2, ignore_bin, img1):\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  h1, w, c = img1.shape\n",
        "  for box in result[0]:\n",
        "    if isNumber1( box[1][0] ):\n",
        "      # For every numeric bounding box we are finding the largest cordinates\n",
        "      xmin = int(min( box[0][0][0] , box[0][1][0] , box[0][2][0] , box[0][3][0] ))\n",
        "      xmax = int(max( box[0][0][0] , box[0][1][0] , box[0][2][0] , box[0][3][0] ))\n",
        "      ymax = int(max( box[0][0][1] , box[0][1][1] , box[0][2][1] , box[0][3][1] ))\n",
        "      ymin = int(min( box[0][0][1] , box[0][1][1] , box[0][2][1] , box[0][3][1] ))\n",
        "      x, y, w, h = (xmin, ymin, xmax - xmin, ymax - ymin)\n",
        "      crop = img1[y:y+h, x:x+w]\n",
        "      # Saving the bounding box as a seperate image \n",
        "      cv2.imwrite('cropped.jpeg',crop)\n",
        "      # Using colorthief to find the second most dominant colors\n",
        "      ct = ColorThief('cropped.jpeg')\n",
        "      col_palette = ct.get_palette(color_count=3)\n",
        "      # Checking HR range and box value as well as the position to confirm for HR\n",
        "      if (check_HR_color_range(col_palette) == True and stoi(box[1][0]) > 42 and (ymax/h1)<0.4):\n",
        "        ignore_bin2.append(box)\n",
        "        return box[1][0]\n",
        "  return \"\"\n",
        "  # Detecting SpO2 with keywords\n",
        "def detect_spo2(threshold, result, ignore_bin2, ignore_bin):\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "  lst = [ \"sp02\", \"spo2\" , \"spoz\" , \"sp0z\" , \"po2\" , \"p02\" , \"poz\" , \"p0z\",\"5po2\" , \"5poz\", \"5p0z\" , \"5p02\" , \"sp0\" , \"spo\" , \"5p0\" , \"5po\" ]\n",
        "  ans = 1000000\n",
        "  num = -1\n",
        "  sp_bin = list()\n",
        "  for idx in range(len(result)):\n",
        "      res = result[idx]\n",
        "      for line in res:\n",
        "        # Checking if keyword is found or not\n",
        "          if(checkIfPresent(line[1][0], lst) and \"source\" not in line[1][0].lower() ):\n",
        "              #flag_rr = 1\n",
        "              A_cor = line[0]\n",
        "              ans = 1000000\n",
        "              for line in res:\n",
        "                  if(line[1][0].isdigit()):\n",
        "                      B_cor = line[0]\n",
        "                      dis = shortest_distance_between_two_bounding_boxes(A_cor,B_cor)\n",
        "                      if(dis < ans):\n",
        "                          ans = dis\n",
        "                          sp_bin = line\n",
        "                          num = line[1][0]\n",
        "  if(ans < threshold):\n",
        "      ignore_bin2.append(sp_bin)\n",
        "      return num\n",
        "  \n",
        "  return -1\n",
        "    \n",
        "def check_HR_color_range(col_palette):\n",
        "  Red_1 = col_palette[1][0]\n",
        "  Green_1 = col_palette[1][1]\n",
        "  Blue_1 = col_palette[1][2]\n",
        "  Red_2 = col_palette[2][0]\n",
        "  Green_2 = col_palette[2][1]\n",
        "  Blue_2 = col_palette[2][2]\n",
        "\n",
        "  if ( (Green_1 + Green_2) > (Blue_1 + Blue_2) and (Green_1 + Green_2) > (Red_1 + Red_2) ):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzKgR8QwLcBO"
      },
      "source": [
        "#*Complete code to extract vitals*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds-29hTN-VCs"
      },
      "outputs": [],
      "source": [
        "def main_func1(img_path, imAge):\n",
        "  ignore_bin = list()\n",
        "  ignore_bin2 = list()\n",
        "  icu_res = dict()\n",
        "  mapElSize = float()\n",
        "  #Denoises the image\n",
        "  imAge = cv2.fastNlMeansDenoisingColored(imAge,None,10,10,7,21)\n",
        "  imAge=cv2.cvtColor(imAge, cv2.COLOR_BGR2RGB)\n",
        "  #using PaddleOCR and storing reault in result\n",
        "  result = ocr.ocr(imAge, cls=True)\n",
        "  #Using normalize function to calculate maximum box size \n",
        "  maxElSize = normalize(result)\n",
        "  #Using 0.35 of the maximum box size as the threshold\n",
        "  threshDelete(0.35, maxElSize, result)\n",
        "  #First We detect the HR\n",
        "  value8 = detect_hr(40, result, ignore_bin2, ignore_bin)\n",
        "  #If that value is detected then we store it in icu_res dict\n",
        "  if value8 != -1 :\n",
        "    ignore_bin.append( value8 )\n",
        "    value8 = value8[0:3]\n",
        "    icu_res[\"hr\"] = value8\n",
        "  #If it is not detected above then we use the general color logic\n",
        "  if \"hr\" not in icu_res:\n",
        "    value9 = detect_hr_color(result, ignore_bin2, ignore_bin, imAge)\n",
        "    if value9 != \"\" :\n",
        "      ignore_bin.append(value9)\n",
        "      value9 = value9[0:3]\n",
        "      icu_res[\"hr\"] = value9\n",
        "  #Here we detect the RR and store it in dict\n",
        "  value7 = detect_rr(40, result, ignore_bin2, ignore_bin)\n",
        "  if value7 != -1 :\n",
        "    icu_res[\"rr\"] = value7\n",
        "    ignore_bin.append( icu_res[\"rr\"] )\n",
        "  #Here we detect the spo2 and store it in the dict \n",
        "  value6 = detect_spo2(40, result, ignore_bin2, ignore_bin)\n",
        "  if value6 != -1 :\n",
        "    icu_res[\"spo2\"] = value6\n",
        "    ignore_bin.append( icu_res[\"spo2\"] )\n",
        "  #Here we start the detection of BP using the solvebpfirst1 function  \n",
        "  values1 = solvebpfirst1(result, icu_res, result, maxElSize, ignore_bin2, ignore_bin)\n",
        "  values2 = list()\n",
        "  #If the BP and MAP both are detected then we store it in the icu_res dict\n",
        "  if( values1[0] != \"\" ):\n",
        "      icu_res[\"bp\"] = values1[0]\n",
        "      ignore_bin.append( icu_res[\"bp\"] )\n",
        "      if( values1[1] != \"\" ):\n",
        "          icu_res[\"map\"] = values1[1]\n",
        "          ignore_bin.append( icu_res[\"map\"] )\n",
        "      else:\n",
        "        # If the MAP is not found we use the solve mapnotfound function and store it in the dict\n",
        "          values3 = solveMapNotFound(icu_res, 40, 30, result, ignore_bin2, ignore_bin)[2]\n",
        "          if( values3 != \"\" ): \n",
        "            icu_res[\"map\"] = values3\n",
        "            ignore_bin.append( icu_res[\"map\"] )\n",
        "  else:\n",
        "    # If the BP was not detected in the earlier function then we use solvebpfirst2 to detect the BP value\n",
        "      values2 = solvebpfirst2(40, 30, result, ignore_bin2, ignore_bin)\n",
        "      if( values2[0] != \"\" ):\n",
        "          ignore_bin.append( values2[0] )\n",
        "          ignore_bin.append( values2[1] )\n",
        "          icu_res[\"bp\"] = values2[0] + \"/\" + values2[1]\n",
        "          if( values2[2] != \"\" ):\n",
        "              icu_res[\"map\"] = values2[2]\n",
        "              ignore_bin.append( icu_res[\"map\"] )\n",
        "          else:\n",
        "            # If we are not able to detect the MAP value then use solvemapnotfound to detect map again\n",
        "              values3 = solveMapNotFound(icu_res, 40, 30, result, ignore_bin2, ignore_bin)[2]\n",
        "              if( values3 != \"\" ): \n",
        "                icu_res[\"map\"] = values3\n",
        "                ignore_bin.append( icu_res[\"map\"] )\n",
        "      else:\n",
        "        # If BP was not detected using above function then detect MAP using solvemapnotfound\n",
        "          values4 = solveMapNotFound(icu_res, 40, 30, result, ignore_bin2, ignore_bin)\n",
        "          if( values4[0] != \"\" ):\n",
        "              ignore_bin.append( values4[0] )\n",
        "              ignore_bin.append( values4[1] )\n",
        "              icu_res[\"bp\"] = values4[0] + \"/\" + values4[1]\n",
        "          if( values4[2] != \"\" ):\n",
        "              icu_res[\"map\"] = values4[2]\n",
        "              ignore_bin.append( icu_res[\"map\"] )\n",
        "  # If map and BP were not present in dict then detect BP using solve BP last function \n",
        "  if( \"map\" not in icu_res and \"bp\" not in icu_res ):\n",
        "      values5 = solveBplast(40, result, ignore_bin2, ignore_bin)\n",
        "      if( values5[0] != \"\" ):\n",
        "        ignore_bin.append( values5[0] )\n",
        "      if( values5[1] != \"\" ):\n",
        "        ignore_bin.append( values5[1] )\n",
        "      icu_res[\"bp\"] = values5[1] + \"/\" + values5[0]\n",
        "      icu_res[\"map\"] = values5[2]\n",
        "      if ( values5[2] != \"\" ):\n",
        "        ignore_bin.append( values5[2] )\n",
        "\n",
        "# If map is present in the dict then take the size of the map as threshold\n",
        "  if map in icu_res:\n",
        "    for y in result[0]:\n",
        "      if icu_res[map] == y:\n",
        "        mapElSize = boxSize(y[0])\n",
        "        break\n",
        "\n",
        "  threshDelete(mapElSize / maxElSize, maxElSize, result)\n",
        "\n",
        "  # print(icu_res)  \n",
        "  # value6 = detect_spo2(40)\n",
        "  # if value6 != -1 :\n",
        "  #   icu_res[\"spo2\"] = value6\n",
        "  #   ignore_bin.append( icu_res[\"spo2\"] )\n",
        "# Remove all text\n",
        "  removeAllText(result)\n",
        "  removeBinElements(result, ignore_bin2, ignore_bin)\n",
        "\n",
        "  # print(icu_res)\n",
        "  clear(icu_res)\n",
        "  # for line in result[0]:\n",
        "  #   print(line)\n",
        "  # Prints the dict\n",
        "  # print(icu_res)\n",
        "  # If HR spo2 and rr are not in the dict \n",
        "  if len(result[0]) > 0 and ( \"hr\" not in icu_res or \"spo2\" not in icu_res or \"rr\" not in icu_res ):\n",
        "    if len(result[0]) == 1:\n",
        "      #  If the number is less than 40 it is rr\n",
        "      if stoi(result[0][0][1][0]) < 40 and \"rr\" not in icu_res :\n",
        "        icu_res[\"rr\"] = result[0][0][1][0]\n",
        "      # If the number is greater than 100 it is HR \n",
        "      elif stoi(result[0][0][1][0]) > 100 and \"hr\" not in icu_res:\n",
        "        icu_res[\"hr\"] = result[0][0][1][0]\n",
        "      # If it is 66 detect spo2 as 99\n",
        "      elif ( result[0][0][1][0] == \"66\" ) and \"spo2\" not in icu_res:\n",
        "        icu_res[\"spo2\"] = \"99\"\n",
        "      #  If the number is less than 100 detect it as sp02\n",
        "      elif stoi(result[0][0][1][0]) <= 100 and \"spo2\" not in icu_res:\n",
        "        icu_res[\"spo2\"] = result[0][0][1][0]\n",
        "      elif \"hr\" not in icu_res:\n",
        "        icu_res[\"hr\"] = result[0][0][1][0]\n",
        "    else:\n",
        "      numbers = list()\n",
        "      for x in result[0]:\n",
        "        numbers.append(stoi(x[1][0]))\n",
        "      numbers.sort()\n",
        "      if \"hr\" not in icu_res and \"rr\" not in icu_res and \"spo2\" not in icu_res:\n",
        "        for x in numbers:\n",
        "          if x < 101 and x >90:\n",
        "            icu_res[\"spo2\"] = str(x);\n",
        "            numbers.remove(x)\n",
        "            break;\n",
        "        numbers.sort()\n",
        "        icu_res[\"hr\"] = str(numbers[1])\n",
        "        icu_res[\"rr\"] = str(numbers[0])\n",
        "      elif \"rr\" not in icu_res and \"spo2\" not in icu_res:\n",
        "        if numbers[0] < 45:\n",
        "          icu_res[\"rr\"] = str(numbers[0])\n",
        "          icu_res[\"spo2\"] = str(numbers[1])\n",
        "        else:\n",
        "          icu_res[\"spo2\"] = str(numbers[0])\n",
        "      elif \"hr\" not in icu_res and \"spo2\" not in icu_res:\n",
        "        if numbers[1] >= 90 and numbers[1] < 101:\n",
        "          icu_res[\"hr\"] = str(numbers[0])\n",
        "          icu_res[\"spo2\"] = str(numbers[1])\n",
        "        else:\n",
        "          icu_res[\"hr\"] = str(numbers[1])\n",
        "          icu_res[\"spo2\"] = str(numbers[0])\n",
        "      elif \"hr\" not in icu_res and \"rr\" not in icu_res:\n",
        "        if numbers[0] < 45:\n",
        "          icu_res[\"hr\"] = str(numbers[1])\n",
        "          icu_res[\"rr\"] = str(numbers[0])\n",
        "        else:\n",
        "          icu_res[\"hr\"] = str(numbers[0])\n",
        "      elif \"hr\" not in icu_res:\n",
        "        for y in numbers:\n",
        "          if y > 57:\n",
        "            icu_res[\"hr\"] = str(y)\n",
        "      elif \"spo2\" not in icu_res:\n",
        "        for y in numbers:\n",
        "          if y > 80 and y <= 100:\n",
        "            icu_res[\"spo2\"] = str(y)\n",
        "            break\n",
        "        if \"spo2\" in icu_res:\n",
        "          numbers.remove(int(icu_res[\"spo2\"]))\n",
        "      elif \"rr\" not in icu_res:\n",
        "        for y in numbers:\n",
        "          if y < 46:\n",
        "            icu_res[\"rr\"] = str(y)\n",
        "      if len(numbers) >= 2 and \"sys\" not in icu_res and \"dia\" not in icu_res:\n",
        "        numbers.sort()\n",
        "        icu_res[\"sys\"] = numbers[0]\n",
        "        icu_res[\"dia\"] = numbers[1]\n",
        "      if len(numbers) >= 2 and \"sys\" not in icu_res and \"dia\" not in icu_res and map not in icu_res:\n",
        "        numbers.sort()\n",
        "        icu_res[\"sys\"] = numbers[0]\n",
        "        icu_res[\"map\"] = numbers[1]\n",
        "        icu_res[\"dia\"] = numbers[2]\n",
        "\n",
        "  clear(icu_res)\n",
        "  #Get the icu_res dict in the answer format\n",
        "  capitalise_keys(icu_res)  \n",
        "  # print(icu_res)\n",
        "  # if not icu_res['HR']:\n",
        "  #   heart_rate_graph_detection(imAge,-1)\n",
        "  # else:\n",
        "  #   heart_rate_graph_detection(imAge,stoi(icu_res['HR']))\n",
        "  \n",
        "  return icu_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXRbvE4IJCtE"
      },
      "source": [
        "#*Heart Rate Graph Detetction*\n",
        "- Detect the HR graph in the image by first masking the image for green colour and then finding the contours and determining the contour with the largest perimeter and then plotting it.\n",
        "-If the graph is not found through the above method then it uses neurokit2 library to simulate the graph using HR values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7V5vjm4KEaY"
      },
      "outputs": [],
      "source": [
        "def heart_rate_graph_detection(image,heart_rate_value):\n",
        "  def normal_detect(vis2):\n",
        "    # Convert the image to grayscale\n",
        "    gray = rgb2gray(vis2)\n",
        "    # Get the ECG signal from the grayscale image\n",
        "    signal = np.mean(gray, axis=0)\n",
        "    for i in range(len(signal) - 1, 0, -1):\n",
        "      if signal[i] == 0.0:\n",
        "        signal = np.delete(signal, i)\n",
        "    # Plot the ECG signal\n",
        "    plt.figure(figsize = (25, 5))\n",
        "    plt.plot(signal,color='green')\n",
        "    plt.title('Digitized ECG Signal')\n",
        "    plt.ylabel('Amplitude (mV)')\n",
        "    plt.show()\n",
        "  \n",
        "  def using_neurokit2(heart_rate_value):\n",
        "    if heart_rate_value == -1:\n",
        "      # print('yes')\n",
        "      signal = np.zeros((400), dtype=int)\n",
        "      plt.figure(figsize = (25, 5))\n",
        "      plt.plot(signal,color='green')\n",
        "      plt.title('Digitized ECG Signal')\n",
        "      plt.ylabel('Amplitude (mV)')\n",
        "      plt.show()\n",
        "      return\n",
        "    simulated_ecg = nk.ecg_simulate(duration=7, sampling_rate=1000, heart_rate=heart_rate_value,method=\"simple\")\n",
        "    nk.signal_plot(simulated_ecg, sampling_rate=1000,color='green')\n",
        "  # Load the input image\n",
        "  # image = cv2.imread(\"/content/hcgnagpur_icu_mon--401_2022_10_23_15_30_2.jpeg\")\n",
        "  h1, w1, c = image.shape\n",
        "  # cv2_imshow(image)\n",
        "  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # lower bound and upper bound for Green color\n",
        "  lower_bound = np.array([45, 50, 50])\t \n",
        "  upper_bound = np.array([75, 255, 255])\n",
        "\n",
        "  # find the colors within the boundaries\n",
        "  mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
        "\n",
        "  #define kernel size  \n",
        "  kernel = np.ones((7,7),np.uint8)\n",
        "\n",
        "  # Remove unnecessary noise from mask\n",
        "\n",
        "  mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "  mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "  # Segment only the detected region\n",
        "  segmented_img = cv2.bitwise_and(image, image, mask=mask)\n",
        "  # Convert the image to grayscale\n",
        "  gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
        "  # blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "  # Threshold the image to create a binary image\n",
        "  _, thresholded = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "  # cv2_imshow(thresholded)\n",
        "\n",
        "  # h, w = thresholded.shape[:2]\n",
        "\n",
        "  # Drop top and bottom area of image with black parts.\n",
        "  # thresholded= thresholded[100:h-100, :]\n",
        "  h, w = thresholded.shape[:2]\n",
        "\n",
        "  # Find contours in the binary image\n",
        "  contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = [cv2.approxPolyDP(cnt, 3, True) for cnt in contours]\n",
        "\n",
        "  # Draw all contours\n",
        "  vis = np.zeros((h, w, 3), np.uint8)\n",
        "  cv2.drawContours( vis, contours, -1, (128,255,255), 3, cv2.LINE_AA)\n",
        "\n",
        "  # Draw the contour with maximum perimeter (omitting the first contour which is outer boundary of image\n",
        "  # Not necessary in this case\n",
        "  vis2 = np.zeros((h, w, 3), np.uint8)\n",
        "  perimeter=[]\n",
        "  for cnt in contours[1:]:\n",
        "      perimeter.append(cv2.arcLength(cnt,True))\n",
        "  # print(perimeter)\n",
        "  # print (max(perimeter))\n",
        "  maxindex= perimeter.index(max(perimeter))\n",
        "  # print (maxindex)\n",
        "\n",
        "  cv2.drawContours( vis2, contours, maxindex+1 , (0,255,0), -1)\n",
        "  gray = cv2.cvtColor(vis2, cv2.COLOR_BGR2GRAY)\n",
        "  _, threshold = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
        "  contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  # Select the largest contour\n",
        "  contour = max(contours, key=cv2.contourArea)\n",
        "  x, y, w, h = cv2.boundingRect(contour)\n",
        "  if (w/w1)>0.4:\n",
        "    normal_detect(vis2)\n",
        "  else:\n",
        "    using_neurokit2(heart_rate_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQIRyOw5-ztk"
      },
      "source": [
        "#*Final Function* - \n",
        "- contains the Inference function given in the sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Dfy3RS-18G"
      },
      "outputs": [],
      "source": [
        "def inference(image_path:str) -> dict:\n",
        "    croppedImage = segmentation(image_path)\n",
        "    result = main_func1('/content/cropped.jpeg', croppedImage)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqsP5li4OIHj"
      },
      "source": [
        "#Trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKpOycaROO4U"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "print(inference('/content/medicakolkata_ccu2_mon--5_2022_5_18_5_6_2.jpeg'))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-iQdRC6C6D9v",
        "YhbsxJi8mglo",
        "DyM3baQIgGSI",
        "2BRBzoGu-WcA",
        "2BaJCNbT2ksJ",
        "q-DM7cZsyn2C",
        "qrWEMg-F36iA",
        "VXRbvE4IJCtE",
        "GQIRyOw5-ztk",
        "PqsP5li4OIHj"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}